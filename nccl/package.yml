name       : nccl
version    : 2.4.8
release    : 7
source     :
    - https://github.com/NVIDIA/nccl/archive/v2.4.8-1.tar.gz : e2260da448ebbebe437f74768a346d28c74eabdb92e372a3dc6652a626318924
license    : BSD-3-Clause
component  : programming.library
summary    : Optimized primitives for collective multi-GPU communication
description: |
    NCCL (pronounced "Nickel") is a stand-alone library of standard collective communication routines for GPUs, implementing all-reduce, all-gather, reduce, broadcast, and reduce-scatter. It has been optimized to achieve high bandwidth on platforms using PCIe, NVLink, NVswitch, as well as networking using InfiniBand Verbs or TCP/IP sockets. NCCL supports an arbitrary number of GPUs installed in a single node or across multiple nodes, and can be used in either single- or multi-process (e.g., MPI) applications.
clang      : yes
builddeps  :
    - cuda
environment: |
    export PATH=$PATH:/usr/lib64/cuda/bin
build      : |
    %make src.build CUDA_HOME=%libdir%/cuda
install    : |
    install -dm00755 $installdir/usr/include $installdir/%libdir%
    install -Dm00644 -t $installdir/usr/include build/include/*
    # Preserve symlinks
    cp -rPv build/lib/* $installdir/%libdir%
